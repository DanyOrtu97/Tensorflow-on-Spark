{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import nn, Trainer, loss\n",
    "from mxnet import optimizer\n",
    "from mxnet import autograd, np, npx, gpu\n",
    "npx.set_np()\n",
    "mx.context.num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gpu = npx.gpu() if npx.num_gpus() > 0 else npx.cpu()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras import initializers\n",
    "    from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(320, 320, 1), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(320, 320, 1), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid',kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.Zeros()))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "def fullpath(path, files):\n",
    "    return  [(lambda x: path + x)(x) for x in files]\n",
    "val_dir = \"../chest_xray/chest_xray/test\"\n",
    "filesPneumo = fullpath(val_dir+'/PNEUMONIA/',os.listdir(os.path.join(val_dir, 'PNEUMONIA')))\n",
    "del filesPneumo[0]\n",
    "labelsPneumo = np.zeros(len(filesPneumo))\n",
    "filesNormal = fullpath(val_dir+'/NORMAL/',os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
    "del filesNormal[0]\n",
    "labelsNormal = np.ones(len(filesNormal))\n",
    "fileData = filesPneumo + filesNormal\n",
    "fileLabels = np.concatenate((labelsPneumo,labelsNormal),axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "def convert_keras_to_mxnet(model):\n",
    "    def layer_conversion(layer):\n",
    "        t = str(type(layer)).split(\".\")\n",
    "        layer_type = t[-1].replace('\\'>',\"\")\n",
    "        config = layer.get_config()\n",
    "        if layer_type == \"Dense\":\n",
    "            return nn.Dense(units=config['units'], activation=config['activation'], use_bias=config['use_bias'])\n",
    "        if layer_type == \"Conv2D\":\n",
    "            return nn.Conv2D(channels=config['filters'], kernel_size=config['kernel_size'],use_bias=config['use_bias'],activation=config['activation'], weight_initializer=mx.init.Normal(0.01), bias_initializer=mx.init.Zero())\n",
    "        if layer_type == \"MaxPooling2D\":\n",
    "            return nn.MaxPool2D(pool_size=config['pool_size'])\n",
    "        if layer_type == \"BatchNormalization\":\n",
    "            return nn.BatchNorm(momentum=config['momentum'], epsilon=config['epsilon'])\n",
    "        if layer_type==\"Dropout\":\n",
    "            return nn.Dropout(rate=config['rate'])\n",
    "        if layer_type==\"Flatten\":\n",
    "            return nn.Flatten()\n",
    "        return None\n",
    "    mxModel = nn.HybridSequential()\n",
    "    for layer in model.layers:\n",
    "        new_layer = layer_conversion(layer)\n",
    "        mxModel.add(new_layer)\n",
    "    mxModel.hybridize()\n",
    "    mxModel.initialize(force_reinit=True, init=mx.init.Xavier())\n",
    "    return mxModel\n",
    "\n",
    "new_model = convert_keras_to_mxnet(model)\n",
    "clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'context'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-796afd7b15eb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mnew_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'context'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Ignoring ../chest_xray/chest_xray/test/.DS_Store, which is not a directory.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from mxnet import image\n",
    "def preprocess(img,label):\n",
    "    img = image.imresize(img/ 255.0,320,320).astype(np.float32)\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "        #img = img[np.newaxis, :].astype(np.float32)\n",
    "    return img,label\n",
    "ds2 =  mx.gluon.data.vision.datasets.ImageFolderDataset(\"../chest_xray/chest_xray/test\",transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = mx.gluon.data.DataLoader(ds2, batch_size=16, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def acc(output, label):\n",
    "    # output: (batch, num_output) float32 ndarray\n",
    "    # label: (batch, ) int32 ndarray\n",
    "    #pred = x = np.ones((3,4), ctx=mx.gpu(0))\n",
    "    #pred = pred.reshape(-1,1)\n",
    "    #for i,o in enumerate(output):\n",
    "    #    pred[i] = 0. if o < 0.5 else 1.\n",
    "    o = output.argmax(axis=1)\n",
    "    ok = 0\n",
    "    for i,out in enumerate(o):\n",
    "        if o[i] == label[i].astype('float32'):\n",
    "            ok += 1\n",
    "    return  (ok/len(label))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \n",
      "Loss: nan \n",
      "Acc: 75.000000 \n",
      "Time: 2.527249\n",
      "Epoch 1 \n",
      "Loss: nan \n",
      "Acc: 0.000000 \n",
      "Time: 2.440891\n",
      "Epoch 2 \n",
      "Loss: nan \n",
      "Acc: 100.000000 \n",
      "Time: 2.655742\n",
      "Epoch 3 \n",
      "Loss: nan \n",
      "Acc: 50.000000 \n",
      "Time: 2.583393\n",
      "Epoch 4 \n",
      "Loss: nan \n",
      "Acc: 75.000000 \n",
      "Time: 2.581415\n",
      "Epoch 5 \n",
      "Loss: nan \n",
      "Acc: 50.000000 \n",
      "Time: 2.645513\n",
      "Epoch 6 \n",
      "Loss: nan \n",
      "Acc: 50.000000 \n",
      "Time: 2.323579\n",
      "Epoch 7 \n",
      "Loss: nan \n",
      "Acc: 75.000000 \n",
      "Time: 2.486578\n",
      "Epoch 8 \n",
      "Loss: nan \n",
      "Acc: 0.000000 \n",
      "Time: 2.850910\n",
      "Epoch 9 \n",
      "Loss: nan \n",
      "Acc: 75.000000 \n",
      "Time: 2.629853\n",
      "Epoch 10 \n",
      "Loss: nan \n",
      "Acc: 75.000000 \n",
      "Time: 2.820413\n",
      "Epoch 11 \n",
      "Loss: nan \n",
      "Acc: 100.000000 \n",
      "Time: 2.704699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-fb6d9b96c704>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m                             \u001B[0;31m# calculate training metrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0mtrain_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0macc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m                         \u001B[0;31m# calculate validation accuracy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Epoch %d \"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-8324351afa0e>\u001B[0m in \u001B[0;36macc\u001B[0;34m(output, label)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mok\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mout\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'float32'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m             \u001B[0mok\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mreturn\u001B[0m  \u001B[0;34m(\u001B[0m\u001B[0mok\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/numpy/multiarray.py\u001B[0m in \u001B[0;36m__bool__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    782\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    783\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mnum_elements\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 784\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    785\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    786\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"The truth value of an ndarray with multiple elements is ambiguous.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/numpy/multiarray.py\u001B[0m in \u001B[0;36mitem\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    831\u001B[0m         \"\"\"\n\u001B[1;32m    832\u001B[0m         \u001B[0;31m# TODO(junwu): no need to call asnumpy() on the whole array.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 833\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    834\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    835\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py\u001B[0m in \u001B[0;36masnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2533\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2534\u001B[0m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_as\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_void_p\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2535\u001B[0;31m             ctypes.c_size_t(data.size)))\n\u001B[0m\u001B[1;32m   2536\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2537\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "#new_model.initialize(force_reinit=True, init=mx.init.Xavier(),ctx=mx.cpu(0))\n",
    "#new_model.collect_params().reset_ctx(ctx=mx.cpu(0))\n",
    "with mx.Context(mx.cpu(0)):\n",
    "    accuracy = mx.metric.Accuracy()\n",
    "    HL = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "    trainer = mx.gluon.Trainer(new_model.collect_params(),'sgd', {'learning_rate': 0.0005})\n",
    "    for epoch in range(30):\n",
    "        train_loss, train_acc, valid_acc = 0., 0., 0.\n",
    "        tic = time.time()\n",
    "        for data, label in train_data:\n",
    "                            # forward + backward\n",
    "            with autograd.record():\n",
    "                output = new_model(data.as_in_ctx(mx.cpu(0)))\n",
    "                loss = HL(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(4)\n",
    "                            # calculate training metrics\n",
    "        train_loss = loss.mean()\n",
    "        train_acc = acc(output, label)\n",
    "                        # calculate validation accuracy\n",
    "        print(\"Epoch %d \" % epoch)\n",
    "        print(\"Loss: %f \" % train_loss)\n",
    "        print(\"Acc: %f \" % train_acc)\n",
    "        print(\"Time: %f\" % (time.time()-tic))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5309792256, 8366784512)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.context.gpu_memory_info(device_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.584525, train acc 0.724, in 84.8 sec\n",
      "Epoch 1: loss 0.522646, train acc 0.870, in 84.4 sec\n",
      "Epoch 2: loss 0.504782, train acc 0.912, in 83.5 sec\n",
      "Epoch 3: loss 0.496503, train acc 0.925, in 81.2 sec\n",
      "Epoch 4: loss 0.486344, train acc 0.944, in 83.6 sec\n",
      "Epoch 5: loss 0.480784, train acc 0.958, in 95.9 sec\n",
      "Epoch 6: loss 0.476909, train acc 0.965, in 102.3 sec\n",
      "Epoch 7: loss 0.473780, train acc 0.973, in 101.6 sec\n",
      "Epoch 8: loss 0.469474, train acc 0.981, in 100.7 sec\n",
      "Epoch 9: loss 0.468436, train acc 0.987, in 98.6 sec\n",
      "Epoch 10: loss 0.469112, train acc 0.986, in 98.4 sec\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrea/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-ec2cdf6330a7>\", line 25, in <module>\n",
      "    train_acc += acc2(output, label)\n",
      "  File \"<ipython-input-8-ec2cdf6330a7>\", line 6, in acc2\n",
      "    pred[i] = 0. if o < 0.5 else 1.\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mxnet/numpy/multiarray.py\", line 784, in __bool__\n",
      "    return bool(self.item())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mxnet/numpy/multiarray.py\", line 833, in item\n",
      "    return self.asnumpy().item(*args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py\", line 2535, in asnumpy\n",
      "    ctypes.c_size_t(data.size)))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrea/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrea/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/andrea/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/andrea/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m"
     ]
    }
   ],
   "source": [
    "def acc2(output, label):\n",
    "    # output: (batch, num_output) float32 ndarray\n",
    "    # label: (batch, ) int32 ndarray\n",
    "    pred = np.zeros(len(output))\n",
    "    for i,o in enumerate(output):\n",
    "        pred[i] = 0. if o < 0.5 else 1.\n",
    "    return (pred ==\n",
    "            label.astype('float32')).mean()\n",
    "\n",
    "HL = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "trainer = mx.gluon.Trainer(new_model.collect_params(),'sgd', {'learning_rate': 0.0005})\n",
    "for epoch in range(30):\n",
    "    train_loss, train_acc, valid_acc = 0., 0., 0.\n",
    "    tic = time.time()\n",
    "    for data, label in train_data:\n",
    "            # forward + backward\n",
    "        with autograd.record():\n",
    "            output = new_model(data)\n",
    "            loss = HL(output.astype(np.float64), label.astype(np.float64))\n",
    "        loss.backward()\n",
    "            # update parameters\n",
    "        trainer.step(16)\n",
    "            # calculate training metrics\n",
    "        train_loss += loss.mean()\n",
    "        train_acc += acc2(output, label)\n",
    "        # calculate validation accuracy\n",
    "    print(\"Epoch %d: loss %f, train acc %.3f, in %.1f sec\" % (\n",
    "                epoch, train_loss/len(train_data), train_acc/len(train_data), time.time()-tic))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ee7edc48",
   "language": "python",
   "display_name": "PyCharm (BigData)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}